{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import csv\n",
    "from csv import reader, writer, DictWriter\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/michaelfelzan/Desktop/runck_lab/WT_Outputted_CSV_Logs'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enter local directory path to SD cards here:\n",
    "workindir = r'/Users/michaelfelzan/Desktop/runck_lab/WT_Outputted_CSV_Logs'\n",
    "os.chdir(workindir)\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winter_Turf_Type_B_-_6\n",
      "Winter_Turf_Type_B_-_1\n",
      "Winter_Turf_Type_A_-_7\n",
      "Winter_Turf_Type_A_-_8\n",
      "Winter_Turf_Type_A_-_10\n",
      "Winter_Turf_Type_A_-_28\n",
      "Winter_Turf_Type_A_-_17\n",
      "Winter_Turf_Type_A_-_21\n",
      "Winter_Turf_Type_A_-_19\n",
      "Winter_Turf_Type_A_-_26\n",
      "Winter_Turf_Type_A_-_18\n",
      "Winter_Turf_Type_A_-_27\n",
      "Winter_Turf_Type_A_-_20\n",
      "Winter_Turf_Type_A_-_16\n",
      "Winter_Turf_Type_A_-_34\n",
      "Winter_Turf_Type_B_-_12\n",
      "Winter_Turf_Type_A_-_35\n",
      "Winter_Turf_Type_B_-_5\n",
      "Winter_Turf_Type_A_-_3\n",
      "Winter_Turf_Type_A_-_2\n",
      "Winter_Turf_Type_A_-_5\n",
      "Winter_Turf_Type_B_-_4\n",
      "Winter_Turf_Type_A_-_14\n",
      "Winter_Turf_Type_A_-_22\n",
      "Winter_Turf_Type_A_-_23\n",
      "Winter_Turf_Type_A_-_24\n",
      "Winter_Turf_Type_A_-_12\n",
      "Winter_Turf_Type_A_-_15\n",
      "Winter_Turf_Type_B_-_11\n",
      "Winter_Turf_Type_A_-_31\n",
      "Winter_Turf_Type_A_-_36\n"
     ]
    }
   ],
   "source": [
    "node_folders = []\n",
    "\n",
    "for nodefoldername in os.listdir():\n",
    "    if nodefoldername != '.DS_Store':\n",
    "        node_folders.append(nodefoldername)\n",
    "        \n",
    "for folder in node_folders:\n",
    "    print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_nodes = []\n",
    "\n",
    "for nodefold in node_folders:\n",
    "    for subfold in os.listdir(nodefold):\n",
    "        if subfold != \".DS_Store\":\n",
    "            sub_nodes.append((subfold, nodefold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('e00fce685b02f35fe13a0a2d', 'Winter_Turf_Type_B_-_6'),\n",
       " ('e00fce6838cebdf42fc24391', 'Winter_Turf_Type_B_-_1'),\n",
       " ('e00fce682a79a64999b7b409', 'Winter_Turf_Type_A_-_7'),\n",
       " ('e00fce6829163099f836ae78', 'Winter_Turf_Type_A_-_8'),\n",
       " ('e00fce68206506b1159c8936', 'Winter_Turf_Type_A_-_10'),\n",
       " ('e00fce683d1ce7e541f9698f', 'Winter_Turf_Type_A_-_28'),\n",
       " ('e00fce686565dea3e22b623c', 'Winter_Turf_Type_A_-_17'),\n",
       " ('e00fce68af529fe2d2d7c809', 'Winter_Turf_Type_A_-_21'),\n",
       " ('e00fce682d4d9ca0f9a3b12d', 'Winter_Turf_Type_A_-_19'),\n",
       " ('e00fce684b4112eb5390b0a0', 'Winter_Turf_Type_A_-_26'),\n",
       " ('e00fce68e485873e6b6e983b', 'Winter_Turf_Type_A_-_18'),\n",
       " ('e00fce68e5bd8b129dc5e774', 'Winter_Turf_Type_A_-_27'),\n",
       " ('e00fce6867d3a0cda48e32a2', 'Winter_Turf_Type_A_-_20'),\n",
       " ('e00fce682699a15d165801b1', 'Winter_Turf_Type_A_-_16'),\n",
       " ('e00fce687038a71d446ef776', 'Winter_Turf_Type_A_-_34'),\n",
       " ('e00fce68c2bc8e9d3b033655', 'Winter_Turf_Type_A_-_34'),\n",
       " ('e00fce6891afbb6bddd89915', 'Winter_Turf_Type_B_-_12'),\n",
       " ('e00fce6857f0346b44cd699d', 'Winter_Turf_Type_A_-_35'),\n",
       " ('e00fce6856706b033b691f8b', 'Winter_Turf_Type_B_-_5'),\n",
       " ('e00fce6844eb3e18a15dc07f', 'Winter_Turf_Type_A_-_3'),\n",
       " ('e00fce68816c2bc59976cdf2', 'Winter_Turf_Type_A_-_2'),\n",
       " ('e00fce68c014249653ebc049', 'Winter_Turf_Type_A_-_5'),\n",
       " ('e00fce682c26b88b84ab26f2', 'Winter_Turf_Type_B_-_4'),\n",
       " ('e00fce68428e95de642bb0d9', 'Winter_Turf_Type_A_-_14'),\n",
       " ('e00fce68d387c98c80fc79bc', 'Winter_Turf_Type_A_-_22'),\n",
       " ('e00fce68f5490112d61bdccb', 'Winter_Turf_Type_A_-_23'),\n",
       " ('e00fce68a0322349e64ec178', 'Winter_Turf_Type_A_-_24'),\n",
       " ('e00fce681171349b5773ef72', 'Winter_Turf_Type_A_-_24'),\n",
       " ('e00fce68b6dc19eefd628b4e', 'Winter_Turf_Type_A_-_12'),\n",
       " ('e00fce68ccb7400e1fb8aa98', 'Winter_Turf_Type_A_-_15'),\n",
       " ('e00fce68fb8a948ec07bb826', 'Winter_Turf_Type_B_-_11'),\n",
       " ('e00fce6813794773754ac5b9', 'Winter_Turf_Type_A_-_31'),\n",
       " ('e00fce688c30491f7bf87fb2', 'Winter_Turf_Type_A_-_31'),\n",
       " ('e00fce6848a6a48956efa89d', 'Winter_Turf_Type_A_-_36')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s, n in sub_nodes:\n",
    "    path_to_subn = os.path.join(workindir,n,s)\n",
    "    itercsvs = []\n",
    "    for file in os.listdir(path_to_subn):\n",
    "        if \".csv\" in file:\n",
    "            itercsvs.append(os.path.join(path_to_subn, file))\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    allheaders_in_subf = []\n",
    "    \n",
    "    for csv_f in itercsvs:\n",
    "        with open(csv_f) as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "            iter_header = next(csv_reader)\n",
    "            allheaders_in_subf.append(tuple(iter_header))\n",
    "    \n",
    "    seen = set()\n",
    "    dupes = []\n",
    "    \n",
    "    for header in allheaders_in_subf:\n",
    "            if header in seen:\n",
    "                if header not in dupes:\n",
    "                    dupes.append(header)\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                seen.add(header)\n",
    "    \n",
    "    if dupes != []:\n",
    "        merge_dir_indicies = []\n",
    "        for f, s in enumerate(dupes):\n",
    "            merge_dir_indicies.append(f)\n",
    "            \n",
    "        \n",
    "        for mergeindx in merge_dir_indicies:\n",
    "            iter_mergefold_name = os.path.join(\n",
    "                path_to_subn,\n",
    "                f\"merge_dir_{mergeindx}\"\n",
    "            )\n",
    "            if os.path.exists(iter_mergefold_name) == False:\n",
    "                os.mkdir(iter_mergefold_name)\n",
    "        \n",
    "        for csv_f in itercsvs:\n",
    "            with open(csv_f) as csv_file:\n",
    "                csv_reader = csv.reader(csv_file, delimiter = ',')\n",
    "                itrheader = tuple(next(csv_reader))\n",
    "                \n",
    "                for indx in dict(enumerate(dupes)):\n",
    "                    if dict(enumerate(dupes))[indx] == itrheader:\n",
    "                        iter_merge_dir = f\"merge_dir_{indx}\"\n",
    "                        iterpathtosubn = path_to_subn\n",
    "                        iterfilename = csv_f\n",
    "                        splitfilename = (iterfilename.split(\n",
    "                            iterpathtosubn)[1]).split(\n",
    "                                r'/')[1]\n",
    "                        iter_copyfile_path = os.path.join(\n",
    "                            path_to_subn,\n",
    "                            iter_merge_dir,\n",
    "                            splitfilename)\n",
    "\n",
    "                        \n",
    "                        if os.path.exists(iter_copyfile_path) == False:     #if file isnt already in merge dir,\n",
    "                            with open(iter_copyfile_path, 'wb') as outfile: #copy it to there \n",
    "                                with open(csv_f, 'rb') as infile:\n",
    "                                    shutil.copyfileobj(infile, outfile)\n",
    "                                    print(f\"Copied {iter_copyfile_path} to {iter_merge_dir}\")\n",
    "                                    \n",
    "                                    #if os.path.exists(iter_copyfile_path)\n",
    "                                    \n",
    "                        if os.path.exists(csv_f) == True:                     #if og file exists...\n",
    "                            if os.path.exists(iter_copyfile_path) == True:     #and merge dir file exists...\n",
    "                                with open(iter_copyfile_path, 'rb') as indirfile: \n",
    "                                    with open(csv_f, 'rb') as ogplacement:\n",
    "                                        if indirfile.readline() == ogplacement.readline(): #and they are the same files...\n",
    "                                            os.remove(csv_f)\n",
    "                                            print(f\"removed {csv_f}, as it exists in merge dir\")\n",
    "                                        else:\n",
    "                                            print(f\"Did not remove \\n    {csv_f} \\nfrom base of subnode folder, as the\"\n",
    "                                                  + f\" contents do not match that of \\n    {iter_copyfile_path}!\")\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "['Logs_2000-00-01.csv', 'Logs_2020-11-17_to_2021-11-29.csv']\n",
      " in folder Winter_Turf_Type_B_-_1, e00fce6838cebdf42fc24391, merge_dir_0\n",
      " have been successfully merged together\n",
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "['Logs_2001-01-01.1.csv', 'Logs_2021-12-10_to_2022-02-26.csv']\n",
      " in folder Winter_Turf_Type_A_-_8, e00fce6829163099f836ae78, merge_dir_1\n",
      " have been successfully merged together\n",
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "['Logs_2000-00-00.csv', 'Logs_2165-25-45_to_2020-11-14.csv']\n",
      " in folder Winter_Turf_Type_A_-_8, e00fce6829163099f836ae78, merge_dir_0\n",
      " have been successfully merged together\n",
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "['Logs_2000-00-00.csv', 'Logs_2021-11-11_to_2021-12-01.csv']\n",
      " in folder Winter_Turf_Type_B_-_12, e00fce6891afbb6bddd89915, merge_dir_0\n",
      " have been successfully merged together\n",
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "['Logs_2001-01-01.1.csv', 'Logs_2021-12-10_to_2022-01-29.csv']\n",
      " in folder Winter_Turf_Type_A_-_5, e00fce68c014249653ebc049, merge_dir_0\n",
      " have been successfully merged together\n",
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "['Logs_2001-01-01.csv', 'Logs_2020-11-20_to_2021-04-04.csv']\n",
      " in folder Winter_Turf_Type_B_-_4, e00fce682c26b88b84ab26f2, merge_dir_1\n",
      " have been successfully merged together\n",
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "['Logs_2001-01-01.1_to_2021-11-02.1.csv', 'Logs_2001-01-02.csv', 'Logs_2021-12-01.csv']\n",
      " in folder Winter_Turf_Type_B_-_4, e00fce682c26b88b84ab26f2, merge_dir_0\n",
      " have been successfully merged together\n",
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "['Logs_2000-00-00_to_2165-25-45.csv', 'Logs_2021-12-11_to_2021-12-12.csv']\n",
      " in folder Winter_Turf_Type_A_-_12, e00fce68b6dc19eefd628b4e, merge_dir_1\n",
      " have been successfully merged together\n",
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "['Logs_2000-00-21_to_2000-00-01.csv', 'Logs_2020-11-14_to_2020-12-25.csv']\n",
      " in folder Winter_Turf_Type_A_-_12, e00fce68b6dc19eefd628b4e, merge_dir_0\n",
      " have been successfully merged together\n",
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "['Logs_2000-00-01_to_2021-11-00.csv', 'Logs_2020-11-17_to_2021-11-16.csv']\n",
      " in folder Winter_Turf_Type_B_-_11, e00fce68fb8a948ec07bb826, merge_dir_0\n",
      " have been successfully merged together\n",
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n"
     ]
    }
   ],
   "source": [
    "for s, n in sub_nodes:\n",
    "    path_to_subn = os.path.join(workindir,n,s)\n",
    "    for file in os.listdir(path_to_subn):\n",
    "        if \"merge_dir_\" in file:\n",
    "            path_to_merge_dir = os.path.join(\n",
    "                path_to_subn,\n",
    "                file)\n",
    "            listofmergedir_files = os.listdir(path_to_merge_dir)\n",
    "            merge_dir_no = path_to_merge_dir.split(\"merge_dir_\")[1]\n",
    "            \n",
    "            concatCSV = os.path.join(path_to_merge_dir,\n",
    "                                     f\"concatCSV_{merge_dir_no}.csv\")\n",
    "            \n",
    "            if os.path.exists(concatCSV) == False: \n",
    "                allFiles = glob.glob(path_to_merge_dir + \"/*.csv\")\n",
    "                allFiles.sort()\n",
    "                with open(concatCSV, 'wb') as outfile:\n",
    "                    for i, fname in enumerate(allFiles):\n",
    "                        with open(fname, 'rb') as infile:\n",
    "                            if i != 0:\n",
    "                                infile.readline()  # Throw away header on all but first file\n",
    "                            shutil.copyfileobj(infile, outfile) # Block copy rest of file from input to output without parsing\n",
    "                trimmednames = []\n",
    "                for csvfil in allFiles:\n",
    "                    trimmednames.append(\n",
    "                        csvfil.split(f\"{path_to_merge_dir}/\")[1]\n",
    "                    )\n",
    "                print(\"     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\\n\"\n",
    "                      f\"{trimmednames}\"\n",
    "                      f\"\\n in folder {n}, {s}, merge_dir_{merge_dir_no}\"\n",
    "                      f\"\\n have been successfully merged together\"\n",
    "                      \"\\n     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatCSV_0.csv was moved to base of subnode folder\n",
      " /Users/michaelfelzan/Desktop/runck_lab/WT_Outputted_CSV_Logs/Winter_Turf_Type_B_-_1/e00fce6838cebdf42fc24391/concatCSV_0.csv\n",
      "concatCSV_1.csv was moved to base of subnode folder\n",
      " /Users/michaelfelzan/Desktop/runck_lab/WT_Outputted_CSV_Logs/Winter_Turf_Type_A_-_8/e00fce6829163099f836ae78/concatCSV_1.csv\n",
      "concatCSV_0.csv was moved to base of subnode folder\n",
      " /Users/michaelfelzan/Desktop/runck_lab/WT_Outputted_CSV_Logs/Winter_Turf_Type_A_-_8/e00fce6829163099f836ae78/concatCSV_0.csv\n",
      "concatCSV_0.csv was moved to base of subnode folder\n",
      " /Users/michaelfelzan/Desktop/runck_lab/WT_Outputted_CSV_Logs/Winter_Turf_Type_B_-_12/e00fce6891afbb6bddd89915/concatCSV_0.csv\n",
      "concatCSV_0.csv was moved to base of subnode folder\n",
      " /Users/michaelfelzan/Desktop/runck_lab/WT_Outputted_CSV_Logs/Winter_Turf_Type_A_-_5/e00fce68c014249653ebc049/concatCSV_0.csv\n",
      "concatCSV_1.csv was moved to base of subnode folder\n",
      " /Users/michaelfelzan/Desktop/runck_lab/WT_Outputted_CSV_Logs/Winter_Turf_Type_B_-_4/e00fce682c26b88b84ab26f2/concatCSV_1.csv\n",
      "concatCSV_0.csv was moved to base of subnode folder\n",
      " /Users/michaelfelzan/Desktop/runck_lab/WT_Outputted_CSV_Logs/Winter_Turf_Type_B_-_4/e00fce682c26b88b84ab26f2/concatCSV_0.csv\n",
      "concatCSV_1.csv was moved to base of subnode folder\n",
      " /Users/michaelfelzan/Desktop/runck_lab/WT_Outputted_CSV_Logs/Winter_Turf_Type_A_-_12/e00fce68b6dc19eefd628b4e/concatCSV_1.csv\n",
      "concatCSV_0.csv was moved to base of subnode folder\n",
      " /Users/michaelfelzan/Desktop/runck_lab/WT_Outputted_CSV_Logs/Winter_Turf_Type_A_-_12/e00fce68b6dc19eefd628b4e/concatCSV_0.csv\n",
      "concatCSV_0.csv was moved to base of subnode folder\n",
      " /Users/michaelfelzan/Desktop/runck_lab/WT_Outputted_CSV_Logs/Winter_Turf_Type_B_-_11/e00fce68fb8a948ec07bb826/concatCSV_0.csv\n"
     ]
    }
   ],
   "source": [
    "for s, n in sub_nodes:\n",
    "    path_to_subn = os.path.join(workindir,n,s)\n",
    "    for file in os.listdir(path_to_subn):\n",
    "        if \"merge_dir_\" in file:\n",
    "            path_to_merge_dir = os.path.join(\n",
    "                path_to_subn,\n",
    "                file)\n",
    "            listofmergedir_files = os.listdir(path_to_merge_dir)\n",
    "            for mergedirfile in listofmergedir_files:\n",
    "                if \"concatCSV\" in mergedirfile:\n",
    "                    og_dest_concatCSV = os.path.join(\n",
    "                        path_to_merge_dir,\n",
    "                        mergedirfile\n",
    "                    )\n",
    "                    \n",
    "                    new_dest_concatCSV = os.path.join(\n",
    "                        path_to_subn,\n",
    "                        mergedirfile\n",
    "                    )\n",
    "                    \n",
    "                    shutil.move(\n",
    "                        og_dest_concatCSV,\n",
    "                        new_dest_concatCSV\n",
    "                    )\n",
    "                    \n",
    "                    print(f\"{mergedirfile} was moved to base of subnode folder\"\n",
    "                         f\"\\n {new_dest_concatCSV}\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
